### 字符编码
你是否认为“ASCII码 = 一个字符就是8比特”？你是否认为一个字节就是一个字符,一个字符就是8比特？你是否还认为你是否还认为utf-8和unicode是统一层面上的概念？如果真的是这样请你认真读完这篇文章

###为什么要有编码？
首先大家需要明确的是在计算机里所有的数据都是字节的形式存储，处理的。我们需要这些字节来表示计算机里的信息。但是这些字节本身又是没有任何意义的，所以我们需要对这些字节赋予实际的意义。所以才会制定各种编码标准。

###编码模型 
首先需要明确的是存在两种编码模型  
#####简单字符集
在这种编码模型里，一个字符集定义了这个字符集里包含什么字符，同时把每个字符如何对应成计算机里的比特也进行了定义。例如ASCII，在ASCII里直接定义了`A -> 0100 0001`。
#####现代编码模型
在现代编码模型里要知道一个字符如何映射成计算机里比特，需要经过如下几个步骤。

1. 知道一个系统需要支持哪些字符，这些字符的集合被称为字符表（Character repertoire）  
2. 给字符表里的抽象字符编上一个数字，也就是字符集合到一个整数集合的映射。这种映射称为编码字符集（CCS:Coded Character Set）,unicode是属于这一层的概念，跟计算机里的什么进制啊没有任何关系，它是完全数学的抽象的。   
3. 将CCS里字符对应的整数转换成计算机里的比特值，便于以后计算机进行表示，存储。这个对应关系被称为字符编码表（CEF:Character Encoding Form）utf-8, utf-16都属于这层。  
4. 对于CEF得到的比特值具体如何在计算机中进行存储，传输。因为存在大端小端的问题，这就会跟具体的操作系统相关了。这种解决方案称为字符编码方案（CES:Character Encoding Scheme）。  

平常我们所说的编码都在第三步的时候完成了,都没有涉及到CES。所以CES并不在本文的讨论范围之内。  
现在也许有人会想为什么要有现代的编码模型？为什么在现在的编码模型要拆分出这么多概念？直接像原始的编码模型直接都规定好所有的信息不行吗？这些问题在下文的编码发展史中都会有所阐述。
###编码的发展史
#####ASCII
ASCII出现在上个世纪60年代的美国，ASCII一共定义了128个字符，使用了一个字节的7位。定义的这些字符包括英文字母A-Z，a-z，数字0-9，一些标点符号和控制符号。在Shell里输入`man ASCII`，可以看到完整的ASCII字符集。ASCII采用的编码模型是简单字符集，它直接定义了一个字符的比特值表示。里例如上文提到的`A -> 0100 0001`。也就是ASCII直接完成了现代编码模型的前三步工作。  
在英语系国家里ASCII标准很完美。但是不要忘了世界上可有好几千种语言，这些语言里不仅只有这些符号啊。如果使用这些语言的人也想使用计算机，ASCII就远远不够了。到这里编码进入了混乱的时代。
#####混乱时代
人们知道计算机的一个字节是8位，可以表示256个字符。ASCII却只使用了7位，所以人们决定把剩余的一位也利用起来。这时问题出现了，人们对于已经规定好的128个字符是没有异议的，但是不同语系的人对于其他字符的需求是不一样的，所以对于剩下的128个字符的扩展会千奇百怪。而且更加混乱的是，在亚洲的语言系统中有更多的字符，一个字节无论如何也满足不了需求了。于是就又产生了各种多字节的表示一个字符方法(gbk就是其中一种)，这就使整个局面更加的混乱不堪。（希望看到这里的你不再认为一个字节就是一个字符，一个字符就是8比特）
#####Unicode
